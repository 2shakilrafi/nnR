% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Nrm.R
\name{Nrm}
\alias{Nrm}
\title{Nrm}
\usage{
Nrm(d)
}
\arguments{
\item{d}{the dimensions of the vector being normed.}
}
\value{
a neural network that takes the 1-norm of a vector of
size d.under ReLU activation. This is the neural network that is:
\deqn{
\mathsf{Nrm}^1_1 = \left( \left( \begin{bmatrix} 1 \\ -1\end{bmatrix},
\begin{bmatrix} 0 \\ 0 \end{bmatrix}\right), \left( \begin{bmatrix}1 && 1\end{bmatrix},
\begin{bmatrix}0\end{bmatrix}\right) \right) \in \left( \mathbb{R}^{2 \times 1} \times
\mathbb{R}^2 \right) \times \left( \mathbb{R}^{1 \times 2} \times \mathbb{R}^1 \right) \quad d=1 \\
\mathsf{Nrm}_1^d = \mathsf{Sum}_{d,1} \bullet \left[ \boxminus_{i=1}^d \mathsf{Nrm}_1^1 \right] \quad d>1
}



\emph{Note:} This function is split into two cases
much like the definition itself.
}
\description{
A function that creates the \eqn{\mathsf{Nrm}} neural networks.that take
the 1- norm of a \eqn{d}-dimensional vector when instantiated with ReLU
activation.
}
\references{
Lemma 4.2.1. Jentzen, A., Kuckuck, B., and von Wurstemberger, P. (2023).
Mathematical introduction to deep learning: Methods, implementations,
and theory. \url{https://arxiv.org/abs/2310.20360}
}
